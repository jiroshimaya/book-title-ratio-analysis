"""
b_rawã”ã¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
local/titles_extracted.csvã‹ã‚‰b_rawã«å¯¾ã—ã¦c_valueã®åˆè¨ˆã‚’é›†è¨ˆã—ã€
b_ranking.csvã¨b_ranking.jsonã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import json
from datetime import datetime

import pandas as pd
from sudachipy import tokenizer, dictionary


# Sudachi Tokenizerã®åˆæœŸåŒ–ï¼ˆçŸ­å˜ä½ç”¨ï¼‰
_TOKENIZER_OBJ = dictionary.Dictionary().create()


def extract_last_simple_noun(text: str) -> str:
    """çŸ­å˜ä½ã®å½¢æ…‹ç´ è§£æã§æœ«å°¾ã®å˜ç´”åè©ã‚’æŠ½å‡ºã™ã‚‹

    Args:
        text: å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        æœ«å°¾ã®å˜ç´”åè©ã€ã¾ãŸã¯è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ

    Examples:
        >>> extract_last_simple_noun("é«˜æ ¡ã‚µãƒƒã‚«ãƒ¼")
        "ã‚µãƒƒã‚«ãƒ¼"
        >>> extract_last_simple_noun("é«˜æ ¡é‡çƒ")
        "é‡çƒ"
    """
    if not text:
        return text

    # Aãƒ¢ãƒ¼ãƒ‰ï¼ˆçŸ­å˜ä½ï¼‰ã§å½¢æ…‹ç´ è§£æ
    morphemes = _TOKENIZER_OBJ.tokenize(text, tokenizer.Tokenizer.SplitMode.A)
    morpheme_list = list(morphemes)

    if not morpheme_list:
        return text

    # æœ«å°¾ã‹ã‚‰é¡ã£ã¦æœ€åˆã«è¦‹ã¤ã‹ã£ãŸåè©ã‚’è¿”ã™
    for morpheme in reversed(morpheme_list):
        if morpheme.part_of_speech()[0] == "åè©":
            return morpheme.surface()

    # åè©ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
    return text


def build_b_ranking_csv(extracted: pd.DataFrame) -> pd.DataFrame:
    """b_rawã”ã¨ã«c_valueã®åˆè¨ˆã¨ã‚«ã‚¦ãƒ³ãƒˆã‚’é›†è¨ˆï¼ˆCSVç”¨ï¼‰"""
    if len(extracted) == 0:
        return pd.DataFrame(columns=["b_raw", "c_sum", "n", "examples"])

    # b_rawãŒã‚ã‚‹ã‚‚ã®ã ã‘ã‚’ä½¿ç”¨
    df = extracted.dropna(subset=["b_raw", "c_value"]).copy()

    if len(df) == 0:
        return pd.DataFrame(columns=["b_raw", "c_sum", "n", "examples"])

    # b_rawã”ã¨ã«é›†è¨ˆ
    agg = (
        df.groupby("b_raw")
        .agg(c_sum=("c_value", "sum"), n=("c_value", "count"))
        .sort_values(["c_sum", "n"], ascending=[False, False])
        .reset_index()
    )

    # ä»£è¡¨ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¸Šä½3ä»¶ï¼‰
    examples = (
        df.groupby("b_raw")["title_raw"]
        .apply(lambda s: " / ".join(list(s.head(3))))
        .reset_index()
        .rename(columns={"title_raw": "examples"})
    )

    agg = agg.merge(examples, on="b_raw", how="left")
    return agg


def build_b_ranking_json(extracted: pd.DataFrame) -> dict:
    """b_rawã”ã¨ã«a_rawã®å†…è¨³ã‚‚å«ã‚ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°JSONï¼ˆè©³ç´°ç‰ˆï¼‰"""
    if len(extracted) == 0:
        return {
            "rankings": [],
            "metadata": {
                "total_titles": 0,
                "total_b_categories": 0,
                "generated_at": datetime.now().isoformat(),
            },
        }

    # b_rawã¨a_rawãŒã‚ã‚‹ã‚‚ã®ã ã‘ã‚’ä½¿ç”¨
    df = extracted.dropna(subset=["b_raw", "a_raw", "c_value"]).copy()

    if len(df) == 0:
        return {
            "rankings": [],
            "metadata": {
                "total_titles": len(extracted),
                "total_b_categories": 0,
                "generated_at": datetime.now().isoformat(),
            },
        }

    # a_rawã‚’æ­£è¦åŒ–ï¼ˆæœ«å°¾ã®å˜ç´”åè©ã®ã¿ã‚’æŠ½å‡ºï¼‰
    df["a_normalized"] = df["a_raw"].apply(extract_last_simple_noun)

    # bã”ã¨ã«é›†è¨ˆ
    rankings = []
    for b_val in (
        df.groupby("b_raw")["c_value"].sum().sort_values(ascending=False).index
    ):
        b_df = df[df["b_raw"] == b_val]
        b_c_sum = float(b_df["c_value"].sum())
        b_count = len(b_df)

        # aã”ã¨ã«é›†è¨ˆï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸa_normalizedã‚’ä½¿ç”¨ï¼‰
        a_breakdown = []
        for a_val in (
            b_df.groupby("a_normalized")["c_value"]
            .sum()
            .sort_values(ascending=False)
            .index
        ):
            a_df = b_df[b_df["a_normalized"] == a_val]
            a_c_sum = float(a_df["c_value"].sum())
            a_count = len(a_df)
            titles = a_df["title_raw"].tolist()

            a_breakdown.append(
                {"a": a_val, "c_sum": a_c_sum, "count": a_count, "titles": titles}
            )

        rankings.append(
            {"b": b_val, "c_sum": b_c_sum, "count": b_count, "a_breakdown": a_breakdown}
        )

    return {
        "rankings": rankings,
        "metadata": {
            "total_titles": len(extracted),
            "total_b_categories": len(rankings),
            "generated_at": datetime.now().isoformat(),
        },
    }


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ“Š b_rankingä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)

    # titles_extracted.csvã‚’èª­ã¿è¾¼ã¿
    csv_path = "local/titles_extracted.csv"
    try:
        extracted = pd.read_csv(csv_path, encoding="utf-8-sig")
        print(f"âœ“ {len(extracted)}ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except FileNotFoundError:
        print(f"âŒ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # CSVå½¢å¼ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆ
    b_ranking_csv = build_b_ranking_csv(extracted)
    csv_output = "local/b_ranking.csv"
    b_ranking_csv.to_csv(csv_output, index=False, encoding="utf-8-sig")
    print(f"âœ“ {csv_output} ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    # JSONå½¢å¼ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆ
    b_ranking_json = build_b_ranking_json(extracted)
    json_output = "local/b_ranking.json"
    with open(json_output, "w", encoding="utf-8") as f:
        json.dump(b_ranking_json, f, ensure_ascii=False, indent=2)
    print(f"âœ“ {json_output} ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    if len(b_ranking_csv) > 0:
        print(f"\nğŸ“ˆ Top 20 (å…¨{len(b_ranking_csv)}ä»¶):")
        print(b_ranking_csv.head(20).to_string(index=False))
    else:
        print("\nâš ï¸  ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—")

    print("\nâœ¨ å®Œäº†!")


if __name__ == "__main__":
    main()
