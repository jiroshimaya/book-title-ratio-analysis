"""Google Books APIã‚’ä½¿ã£ã¦æ›¸ç±æƒ…å ±ã‚’åé›†ãƒ»é›†è¨ˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

main.pyï¼ˆNDLã‚µãƒ¼ãƒç‰ˆï¼‰ã®Google Books APIç‰ˆã€‚
ã€ŒãŒã€‡å‰²ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’åé›†ã—ã€a/b/cã‚’æŠ½å‡ºã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã€‚

Usage:
    uv run main_google_books.py          # å…¨ã‚¯ã‚¨ãƒªã§å®Ÿè¡Œ
    uv run main_google_books.py --force  # æ—¢å­˜CSVã‚’ç„¡è¦–ã—ã¦å†å–å¾—
    uv run main_google_books.py --test   # æœ€å°ã‚µãƒ³ãƒ—ãƒ«ã§å‹•ä½œç¢ºèª
"""

import json
import os
import sys
import time
from datetime import datetime

import pandas as pd

from book_title_ratio_analysis.google_books_client import BookInfo, fetch_all_books
from book_title_ratio_analysis.title_parser import parse_ratio_title

# -----------------------------
# 1) ã‚¯ã‚¨ãƒªä¸€è¦§ï¼ˆintitleãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢ï¼‰
# -----------------------------
QUERIES = [
    # åŠè§’æ•°å­—
    'intitle:"ãŒ1å‰²"',
    'intitle:"ãŒ2å‰²"',
    'intitle:"ãŒ3å‰²"',
    'intitle:"ãŒ4å‰²"',
    'intitle:"ãŒ5å‰²"',
    'intitle:"ãŒ6å‰²"',
    'intitle:"ãŒ7å‰²"',
    'intitle:"ãŒ8å‰²"',
    'intitle:"ãŒ9å‰²"',
    # æ¼¢æ•°å­—
    'intitle:"ãŒä¸€å‰²"',
    'intitle:"ãŒäºŒå‰²"',
    'intitle:"ãŒä¸‰å‰²"',
    'intitle:"ãŒå››å‰²"',
    'intitle:"ãŒäº”å‰²"',
    'intitle:"ãŒå…­å‰²"',
    'intitle:"ãŒä¸ƒå‰²"',
    'intitle:"ãŒå…«å‰²"',
    'intitle:"ãŒä¹å‰²"',
]

SLEEP_SEC = 0.5
OUTPUT_CSV = "local/titles_extracted_google.csv"
OUTPUT_RANKING_CSV = "local/a_ranking_google.csv"
OUTPUT_RANKING_JSON = "local/a_ranking_google.json"


# -----------------------------
# 2) Google Books APIã§æ›¸ç±ã‚’åé›†
# -----------------------------
def harvest_google_books(
    queries: list[str],
    sleep_sec: float = SLEEP_SEC,
) -> pd.DataFrame:
    """å„ã‚¯ã‚¨ãƒªã‹ã‚‰BookInfoã‚’åé›†ã—ã¦DataFrameã‚’è¿”ã™"""
    all_rows: list[dict] = []

    for i, query in enumerate(queries, 1):
        print(f"  [{i}/{len(queries)}] {query}", end=" ", flush=True)
        books = fetch_all_books(query)
        rows = [
            {
                "source": "google_books",
                "title_raw": book.title,
                "authors": ", ".join(book.authors),
                "published_date": book.published_date,
                "isbn": book.isbn,
            }
            for book in books
        ]
        all_rows.extend(rows)
        print(f"â†’ {len(rows)}ä»¶")
        if sleep_sec > 0:
            time.sleep(sleep_sec)

    df = pd.DataFrame(all_rows) if all_rows else pd.DataFrame(
        columns=["source", "title_raw", "authors", "published_date", "isbn"]
    )
    print(f"  ç”Ÿãƒ‡ãƒ¼ã‚¿: {len(df)}ä»¶")
    return df


# -----------------------------
# 3) ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ a/b/c ã‚’æŠ½å‡º
# -----------------------------
def build_rank(df: pd.DataFrame):
    if len(df) == 0:
        empty_extracted = pd.DataFrame(
            columns=["source", "title_raw", "c_value", "c_type", "a_raw", "b_raw"]
        )
        empty_ranking = pd.DataFrame(columns=["a_raw", "c_sum", "n", "examples"])
        return empty_extracted, empty_ranking

    out = df.copy()

    # é‡è¤‡é™¤å»
    original_count = len(out)
    out = out.drop_duplicates(subset=["title_raw"]).reset_index(drop=True)
    if len(out) < original_count:
        print(f"  é‡è¤‡é™¤å»: {original_count}ä»¶ â†’ {len(out)}ä»¶")

    result = out["title_raw"].map(parse_ratio_title)
    out["a_raw"] = result.map(lambda x: x[0])
    out["b_raw"] = result.map(lambda x: x[1])
    out["c_value"] = result.map(lambda x: x[2])
    out["c_type"] = out["c_value"].map(lambda x: "wari" if x is not None else None)

    matched_count = out["c_value"].notna().sum()
    print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: {matched_count}ä»¶ / {len(out)}ä»¶")
    out = out[out["c_value"].notna()].reset_index(drop=True)

    out_ab = out.dropna(subset=["a_raw"]).copy()
    if len(out_ab) == 0:
        return out, pd.DataFrame(columns=["a_raw", "c_sum", "n", "examples"])

    agg = (
        out_ab.groupby("a_raw")
        .agg(c_sum=("c_value", "sum"), n=("c_value", "count"))
        .sort_values(["c_sum", "n"], ascending=[False, False])
        .reset_index()
    )
    examples = (
        out_ab.groupby("a_raw")["title_raw"]
        .apply(lambda s: " / ".join(list(s.head(3))))
        .reset_index()
        .rename(columns={"title_raw": "examples"})
    )
    agg = agg.merge(examples, on="a_raw", how="left")
    return out, agg


def build_ranking_json(extracted: pd.DataFrame) -> dict:
    if len(extracted) == 0:
        return {
            "rankings": [],
            "metadata": {
                "total_titles": 0,
                "total_a_categories": 0,
                "generated_at": datetime.now().isoformat(),
            },
        }

    df = extracted.dropna(subset=["a_raw", "b_raw", "c_value"]).copy()
    if len(df) == 0:
        return {
            "rankings": [],
            "metadata": {
                "total_titles": len(extracted),
                "total_a_categories": 0,
                "generated_at": datetime.now().isoformat(),
            },
        }

    rankings = []
    for a_val in df.groupby("a_raw")["c_value"].sum().sort_values(ascending=False).index:
        a_df = df[df["a_raw"] == a_val]
        b_breakdown = []
        for b_val in a_df.groupby("b_raw")["c_value"].sum().sort_values(ascending=False).index:
            b_df = a_df[a_df["b_raw"] == b_val]
            b_breakdown.append({
                "b": b_val,
                "c_sum": float(b_df["c_value"].sum()),
                "count": len(b_df),
                "titles": b_df["title_raw"].tolist(),
            })
        rankings.append({
            "a": a_val,
            "c_sum": float(a_df["c_value"].sum()),
            "count": len(a_df),
            "b_breakdown": b_breakdown,
        })

    return {
        "rankings": rankings,
        "metadata": {
            "total_titles": len(extracted),
            "total_a_categories": len(rankings),
            "generated_at": datetime.now().isoformat(),
        },
    }


# -----------------------------
# 4) ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# -----------------------------
def main():
    test_mode = "--test" in sys.argv
    force_fetch = "--force" in sys.argv

    os.makedirs("local", exist_ok=True)

    if os.path.exists(OUTPUT_CSV) and not force_fetch:
        print(f"ğŸ“„ æ—¢å­˜ã® {OUTPUT_CSV} ã‚’ä½¿ç”¨ã—ã¾ã™")
        print("   ï¼ˆå†å–å¾—ã™ã‚‹å ´åˆã¯ --force ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼‰")
        extracted = pd.read_csv(OUTPUT_CSV, encoding="utf-8-sig")
        print(f"âœ“ {len(extracted)}ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    else:
        if force_fetch:
            print("ğŸ”„ --force ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šå†å–å¾—ã—ã¾ã™")

        queries = QUERIES[:2] if test_mode else QUERIES
        if test_mode:
            print("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®2ã‚¯ã‚¨ãƒªã®ã¿å®Ÿè¡Œ")
        else:
            print("ğŸ“š æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: å…¨ã‚¯ã‚¨ãƒªã§å®Ÿè¡Œ")

        print(f"ã‚¯ã‚¨ãƒªæ•°: {len(queries)}")
        print("å–å¾—é–‹å§‹...")

        df_titles = harvest_google_books(queries)
        print(f"âœ“ {len(df_titles)}ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—")

        extracted, _ = build_rank(df_titles)
        extracted.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
        print(f"âœ“ {OUTPUT_CSV} ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    _, ranking = build_rank(
        extracted[["source", "title_raw"]].copy()
        if "source" in extracted.columns
        else pd.DataFrame({"source": "google_books", "title_raw": extracted["title_raw"]})
    )

    ranking.to_csv(OUTPUT_RANKING_CSV, index=False, encoding="utf-8-sig")

    ranking_json = build_ranking_json(extracted)
    with open(OUTPUT_RANKING_JSON, "w", encoding="utf-8") as f:
        json.dump(ranking_json, f, ensure_ascii=False, indent=2)

    print("\nSaved:")
    print(f" - {OUTPUT_CSV}")
    print(f" - {OUTPUT_RANKING_CSV}")
    print(f" - {OUTPUT_RANKING_JSON}")

    if len(ranking) > 0:
        print(f"\nTop 20 (å…¨{len(ranking)}ä»¶):")
        print(ranking.head(20).to_string(index=False))
    else:
        print("\nâš ï¸  ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—")

    if test_mode:
        print("\nğŸ’¡ æœ¬ç•ªå®Ÿè¡Œã¯: uv run main_google_books.py")


if __name__ == "__main__":
    main()
